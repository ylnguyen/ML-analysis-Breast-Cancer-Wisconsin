{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python: Exploring features + Machine Learning analysis in the Breast Cancer Wisconsin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The open-source Diagnostic Wisconsin Breast cancer dataset (__[available via Kaggle](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data/discussion)__) contains features of the cell nuclei of malignant and benign tumor cells. The features are computed based on Whole Slide Images of a breast mass. The project's primary challenge is to determine whether a sample is malignant or benign, based on the characteristics in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n",
      "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
      "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Explore data (load in dataframe)\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "print(data.shape)\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consist of 569 tissue samples with 33 columns. However, not every column is a feature. The first step is to \"clean\" the data by removing trivial columns and preparing the prediction labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 32','id'],axis=1,inplace=True)\n",
    "data.diagnosis=[1 if each==\"M\" else 0 for each in data.diagnosis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "X = data.loc[:,data.columns!=\"diagnosis\"]\n",
    "# target\n",
    "y = data.loc[:, \"diagnosis\"]\n",
    "y = y[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    357\n",
      "1    212\n",
      "Name: diagnosis, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our model, we are going to make use of the simple classifiers from ```scikit-learn```, namely the Support Vector Machine, Decision Tree, Gaussian Naive Bayes, Logistic Regression, Random Forest and K-Nearest Neighbors classifiers. However, to make the final model more robust, we are adding some additional steps: nested cross validation, statistical-based feature selection and hyperparameter optimization using a grid search method. Finally, a ROC curve is computed to determine the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "# Reload external modules\n",
    "from importlib import reload\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "outer_cv = 5\n",
    "inner_cv = 3\n",
    "epoch = 30\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold 0\n",
      "Grid search for svm\n",
      "Grid search for tree\n",
      "Grid search for NB\n",
      "Grid search for logistic\n",
      "Grid search for rf\n",
      "Grid search for knn\n",
      "Outer Fold 1\n",
      "Grid search for svm\n",
      "Grid search for tree\n",
      "Grid search for NB\n",
      "Grid search for logistic\n",
      "Grid search for rf\n",
      "Grid search for knn\n",
      "Outer Fold 2\n",
      "Grid search for svm\n",
      "Grid search for tree\n",
      "Grid search for NB\n",
      "Grid search for logistic\n",
      "Grid search for rf\n",
      "Grid search for knn\n",
      "Outer Fold 3\n",
      "Grid search for svm\n",
      "Grid search for tree\n",
      "Grid search for NB\n",
      "Grid search for logistic\n",
      "Grid search for rf\n",
      "Grid search for knn\n",
      "Outer Fold 4\n",
      "Grid search for svm\n",
      "Grid search for tree\n",
      "Grid search for NB\n",
      "Grid search for logistic\n",
      "Grid search for rf\n",
      "Grid search for knn\n"
     ]
    }
   ],
   "source": [
    "# Using a Stratified split to balance uneven classes\n",
    "skf = StratifiedKFold(n_splits=outer_cv)\n",
    "\n",
    "scores = dict()\n",
    "save_models = dict()\n",
    "# Split the dataset into train and test\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
    "    print(f\"Outer Fold {i}\")\n",
    "    X_train, X_test =  X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Statistical-based Feature selection\n",
    "    feat_select = list()\n",
    "    for feature in X_train.columns:\n",
    "        values = X_train[feature]\n",
    "        # Determine whether data is normal distributed\n",
    "        _, p = stats.shapiro(values)\n",
    "        class_0 = np.where(y_train==0)[0]\n",
    "        class_1 = np.where(y_train==1)[0]\n",
    "        if p > alpha:\n",
    "            # Student t-test\n",
    "            _, p_val = stats.ttest_ind(X_train.iloc[class_0,:][feature], X_train.iloc[class_1,:][feature])\n",
    "        else:\n",
    "            # Mann-Whitney U test\n",
    "            _, p_val = stats.mannwhitneyu(X_train.iloc[class_0,:][feature], X_train.iloc[class_1,:][feature])\n",
    "        # Finally, select feature if significant\n",
    "        if p_val < alpha:\n",
    "            feat_select.append(feature)\n",
    "    # Drop insignificant features\n",
    "    X_train, X_test =  X_train[feat_select], X_test[feat_select]\n",
    "    \n",
    "    # Initialize models and parameter grid\n",
    "    models, model_names = initiate_models()\n",
    "    grids = param_grid()\n",
    "    \n",
    "    for model, name, params in zip(models, model_names, grids):\n",
    "        print(f\"Grid search for {name}\")\n",
    "        grid = GridSearchCV(model, params, scoring='accuracy', cv=inner_cv, verbose= False)\n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        if name in save_models:\n",
    "            save_models[name].append(grid)\n",
    "        else:\n",
    "            save_models[name] = [grid]\n",
    "            \n",
    "        # Predictions on test set\n",
    "        y_pred = grid.predict(X_test)\n",
    "        # Evaluation metrics\n",
    "        if name in scores:\n",
    "            scores[name]['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "            scores[name]['accuracy'].append(roc_auc_score(y_test, y_pred))\n",
    "        else:\n",
    "            scores[name] = {\"accuracy\": [accuracy_score(y_test, y_pred)],\n",
    "                            \"auc\": [roc_auc_score(y_test, y_pred)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.873224455187359\n",
      "Test AUC: 0.8296484332350693\n"
     ]
    }
   ],
   "source": [
    "model_names = list(scores.keys())\n",
    "test_accuracy = [scores[name]['accuracy'] for name in model_names]\n",
    "test_auc = [scores[name]['auc'] for name in model_names]\n",
    "print(f'Test accuracy: {np.mean(test_accuracy)}')\n",
    "print(f'Test AUC: {np.mean(test_auc)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
